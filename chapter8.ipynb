{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaY4dumalPqs"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "pipe = pipeline(\"text-classification\", model=bert_ckpt)\n",
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
        "pipe(query)"
      ],
      "metadata": {
        "id": "44iAh1eXlUBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PerformanceBenchmark:\n",
        "  def __init__(self,pipeline,dataset,optim_type=\"BERT baseline\"):\n",
        "    self.pipeline=pipeline\n",
        "    self.dataset=datset\n",
        "    self.optim_type=optim_type\n",
        "  def compute_accuracy(self):\n",
        "    pass\n",
        "  def compute_size(self):\n",
        "    pass\n",
        "  def time_pipeline(self):\n",
        "    pass\n",
        "  def run_benchmark(self):\n",
        "    metrics={}\n",
        "    metrics[self.optim_type]=self.compute_size()\n",
        "    metrics[self.optim_type].update(self.time_pipeline())\n",
        "    metrics[self.optim_type].update(self.compute_accuracy())\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "4lmJucgFldTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dataset"
      ],
      "metadata": {
        "id": "vc7ypvOtmPyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "clinc = load_dataset(\"clinc_oos\", \"plus\")\n",
        "sample = clinc[\"test\"][42]\n",
        "sample"
      ],
      "metadata": {
        "id": "QM0Tdur1mTMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = clinc[\"test\"].features[\"intent\"]\n",
        "intents.int2str(sample[\"intent\"])"
      ],
      "metadata": {
        "id": "vOCtsnSUmWkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "accuracy_score = load_metric(\"accuracy\")"
      ],
      "metadata": {
        "id": "krz_kGYOmY8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(self):\n",
        "\t\"\"\"This overrides the PerformanceBenchmark.compute_accuracy() method\"\"\"\n",
        "\tpreds, labels = [], []\n",
        "\tfor example in self.dataset:\n",
        "\t\tpred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
        "\t\tlabel = example[\"intent\"]\n",
        "\t\tpreds.append(intents.str2int(pred))\n",
        "\t\tlabels.append(label)\n",
        "        accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
        "        print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
        "     return accuracy PerformanceBenchmark.compute_accuracy = compute_accuracy\n"
      ],
      "metadata": {
        "id": "SX6QI-AAmapI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(pipe.model.state_dict().items())[42]"
      ],
      "metadata": {
        "id": "MU2aHmhBmcEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(pipe.model.state_dict(), \"model.pt\")"
      ],
      "metadata": {
        "id": "LEykiJGNmfBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "def compute_size(self):\n",
        "\t\"\"\"This overrides the PerformanceBenchmark.compute_size() method\"\"\"\n",
        "\tstate_dict = self.pipeline.model.state_dict()\n",
        "\ttmp_path = Path(\"model.pt\")\n",
        "\ttorch.save(state_dict, tmp_path)\n",
        "\t# Calculate size in megabytes\n",
        "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
        "    # Delete temporary file\n",
        "    tmp_path.unlink()\n",
        "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
        "    return {\"size_mb\": size_mb}\n",
        "\n",
        " PerformanceBenchmark.compute_size = compute_size\n"
      ],
      "metadata": {
        "id": "8A433W6qmgoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter\n",
        "for _ in range(3):\n",
        "\tstart_time = perf_counter()\n",
        "\t_ = pipe(query)\n",
        "\tlatency = perf_counter() - start_time\n",
        "\tprint(f\"Latency (ms) - {1000 * latency:.3f}\")"
      ],
      "metadata": {
        "id": "4XQD__FtmiG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def time_pipeline(self,query=\"What is the pin number for my account?\"):\n",
        "  latencies=[]\n",
        "  for _ in range(10):\n",
        "    _=self.pipeline(query)\n",
        "  for _ in range(100):\n",
        "    start_time=perf_counter()\n",
        "    _=self.pipeline(query)\n",
        "    latency=perf_counter()-start_time\n",
        "    latencies.append(latency)\n",
        "  time_avg_ms=1000*np.mean(latencies)\n",
        "  time_std_ms=1000*np.std(latencies)\n",
        "  print(f\"Average latency (ms) - {time_avg_ms:.2f}+\\-{time_std_ms:.2f}\")\n",
        "  return {'time_avg_ms':time_avg_ms,\"time_std_ms\":time_std_ms}\n",
        "\n",
        "PerformanceBenchmark.time_pipeline=time_pipeline\n"
      ],
      "metadata": {
        "id": "qnkYTVZgmkPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"])\n",
        "perf_metrics = pb.run_benchmark()"
      ],
      "metadata": {
        "id": "5LVCx7GXnljZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "class DistillationTrainingArguments(TrainingArguments):\n",
        "\tdef __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "\t\tsuper().__init__(*args, **kwargs)\n",
        "\t\tself.alpha = alpha\n",
        "        self.temperature = temperature\n"
      ],
      "metadata": {
        "id": "WLzl4ZRKnopr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer\n",
        "class DistilltionTrainer(Trainer):\n",
        "  def __init__(self,*args,teacher_method=None,**kwargs):\n",
        "    super().__init__(*args,**kwargs)\n",
        "    self.teacher_method=teacher_method\n",
        "  def comput_loss(self,metjod,inputs,return_outputs=False):\n",
        "    outputs_stu=method(**inputs)\n",
        "    loss_ce=outputs_stu.loss\n",
        "    logits_stu=outputs_stu.logits\n",
        "    with torch.no_grad():\n",
        "      outputs_tea=self.teacher_method(**inputs)\n",
        "      logits_tea=outputs_tea.logits\n",
        "    loss_fact=nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_kd=self,args.temperature**2*loss_fact(\n",
        "        F.log_softmax(logits_stu/self.args.temperature,dim=-1),\n",
        "        F.softmax(logits_tea/self.args.temperature,dim=-1)\n",
        "    )\n",
        "  loss=self.args.alpha*loss_ce+(1.-self.args.alpha)*loss_kd\n",
        "  return (loss,outputs_stu) if return_outputs else loss"
      ],
      "metadata": {
        "id": "HujyfggcnprN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "student_ckpt=\"distilbert-base-uncased\"\n",
        "student_tokenizer=AutoTokenizer.from_pretrained(student_ckpt)\n",
        "def tokenize_text(batch):\n",
        "  return student_tokenizer(batch['text'],truncation=True)\n",
        "\n",
        "clinc_enc=clinc,map(tokenize_text,batched=True,remove_columns=['text'])\n",
        "clinc_enc=clinc_enc.rename_column('intent','labels')"
      ],
      "metadata": {
        "id": "swpTPuQ5pMnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "\tpredictions, labels = pred\n",
        "\tpredictions = np.argmax(predictions, axis=1)\n",
        "\treturn accuracy_score.compute(predictions=predictions, references=labels)\n"
      ],
      "metadata": {
        "id": "QhqcNNYsqBsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 48\n",
        "finetuned_ckpt = \"distilbert-base-uncased-finetuned-clinc\"\n",
        "student_training_args = DistillationTrainingArguments(\n",
        "    output_dir=finetuned_ckpt,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    alpha=1,\n",
        "    weight_decay=0.01)\n"
      ],
      "metadata": {
        "id": "f09t0b6tqDta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = pipe.model.config.id2label\n",
        "label2id = pipe.model.config.label2id"
      ],
      "metadata": {
        "id": "PGWlfm6_qLf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "num_labels = intents.num_classes\n",
        "student_config = (AutoConfig .from_pretrained(student_ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id))\n"
      ],
      "metadata": {
        "id": "GYsLaI4aqMpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def student_init():\n",
        "\treturn (AutoModelForSequenceClassification .from_pretrained(student_ckpt, config=student_config).to(device))\n"
      ],
      "metadata": {
        "id": "bsSc_07OqPFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "teacher_model = (AutoModelForSequenceClassification .from_pretrained(teacher_ckpt, num_labels=num_labels) .to(device))\n",
        "distilbert_trainer = DistillationTrainer(model_init=student_init, teacher_model=teacher_model, args=student_training_args, train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'], compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
        "\n",
        "distilbert_trainer.train()\n"
      ],
      "metadata": {
        "id": "fD7SftxDqQxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_ckpt = \"transformersbook/distilbert-base-uncased-finetuned-clinc\"\n",
        "pipe = pipeline(\"text-classification\", model=finetuned_ckpt)\n"
      ],
      "metadata": {
        "id": "hFcZNvKLqSpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim_type = \"DistilBERT\"\n",
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "fnhjFOlHqU8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_metrics(perf_metrics,current_optim_type):\n",
        "  df=pd.DataFrame.form_dict(perf_metrics,orient='index')\n",
        "\n",
        "  for idx in df.index:\n",
        "    df_opt=df.loc[idx]\n",
        "    if idx==current_optim_type:\n",
        "      plt.scatter(df_opt['time_avg_ms'],df_opt['accuracy']*100\n",
        "                  alpha=0.5,s=df_opt['size_mb'],label=idx,marker='$\\u25CC$')\n",
        "    else:\n",
        "      plt.scatter(df_opt['time_avg_ms'],df_opt['accuracy']*100,s=df_opt['size_mb'],label=idx,alpha=0.5)\n",
        "\n",
        "  legend=plt.legend(bbox_to_anchor=(1,1))\n",
        "  for handle in legend.legendHandles:\n",
        "    handle.set_size([20])\n",
        "\n",
        "  plt.ylim(80,90)\n",
        "  xlim=int(perf_metrics['BERT baseline']['time_avg_ms']+3)\n",
        "  plt.xlim(1,xlim)\n",
        "  plt.ylable('Accuracy(%)')\n",
        "  plt.xlabel('Average latency(ms)')\n",
        "  plt.show()\n",
        "plot_metrics(perf_metrics,optim_type)"
      ],
      "metadata": {
        "id": "q_pRG3cgqW7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\tx = trial.suggest_float(\"x\", -2, 2)\n",
        "\ty = trial.suggest_float(\"y\", -2, 2)\n",
        "\treturn (1 - x) ** 2 + 100 * (y - x ** 2) ** 2\n"
      ],
      "metadata": {
        "id": "qVJPS7Bmr4bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=1000)\n"
      ],
      "metadata": {
        "id": "p68Q39Evr50x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "id": "A1NjBHydr6vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hp_space(trial):\n",
        "\treturn {\"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10), \"alpha\": trial.suggest_float(\"alpha\", 0, 1), \"temperature\": trial.suggest_int(\"temperature\", 2, 20)}\n"
      ],
      "metadata": {
        "id": "fzFF1wFqr8zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = distilbert_trainer.hyperparameter_search( n_trials=20, direction=\"maximize\", hp_space=hp_space)\n",
        "print(best_run)"
      ],
      "metadata": {
        "id": "MT5TCStSr964"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in best_run.hyperparameters.items():\n",
        "  setattr(student_training_args,k,v)\n",
        "\n",
        "distilled_ckpt='distilbert-base-uncased-distilled-clinc'\n",
        "\n",
        "student_training_args.output_dir=distilled_ckpt\n",
        "\n",
        "distil_trainer=DistillationTrainer(model_init=student_init,\n",
        "        teacher_model=teacher_method,args=student_training_args,\n",
        "        train_dataset=clinc_enc['train'],eval_dataset=clinc_enc['validation'],\n",
        "        compute_metrics=compute_metrics,tokenizer=student_tokenizer)\n",
        "\n",
        "distil_trainer.train()                                         )"
      ],
      "metadata": {
        "id": "OeBm69JzsA8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distilled_ckpt = \"transformersbook/distilbert-base-uncased-distilled-clinc\"\n",
        "pipe = pipeline(\"text-classification\", model=distilled_ckpt)\n",
        "optim_type = \"Distillation\"\n",
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())\n",
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "ALsfolwOtfC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "state_dict = pipe.model.state_dict()\n",
        "weights = state_dict[\"distilbert.transformer.layer.0.attention.out_lin.weight\"]\n",
        "\n",
        "plt.hist(weights.flatten().numpy(), bins=250, range=(-0.3,0.3), edgecolor=\"C0\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2S2jdlv5tkzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_point = 0\n",
        "scale = (weights.max() - weights.min()) / (127 - (-128))\n"
      ],
      "metadata": {
        "id": "VTIcHZRdtmLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(weights / scale + zero_point).clamp(-128, 127).round().char()"
      ],
      "metadata": {
        "id": "epAcly0Jtn1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import quantize_per_tensor\n",
        "dtype = torch.qint8\n",
        "quantized_weights = quantize_per_tensor(weights, scale, zero_point, dtype)\n",
        "quantized_weights.int_repr()"
      ],
      "metadata": {
        "id": "rWRYSElCto8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "weights @ weights\n",
        "393 μs ± 3.84 μs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
      ],
      "metadata": {
        "id": "2m5z9hZ1ts7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.quantized import QFunctional\n",
        "\n",
        "q_fn = QFunctional()"
      ],
      "metadata": {
        "id": "H-jqp-DHtw9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "q_fn.mul(quantized_weights, quantized_weights)\n",
        "23.3 μs ± 298 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
      ],
      "metadata": {
        "id": "r4EHas1EtyH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.getsizeof(weights.storage()) / sys.getsizeof(quantized_weights.storage())\n"
      ],
      "metadata": {
        "id": "cYEE_WnDtzxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.quantization import quantize_dynamic\n",
        "model_ckpt = \"transformersbook/distilbert-base-uncased-distilled-clinc\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = (AutoModelForSequenceClassification .from_pretrained(model_ckpt).to(\"cpu\"))\n",
        "model_quantized = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n"
      ],
      "metadata": {
        "id": "oa4BoFLUt12Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-classification\", model=model_quantized, tokenizer=tokenizer)\n",
        "optim_type = \"Distillation + quantization\"\n",
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())\n",
        "\n",
        "Model size (MB) - 132.40\n",
        "Average latency (ms) - 12.54 +\\- 0.73\n",
        "Accuracy on test set - 0.876\n",
        "\n",
        "plot_metrics(perf_metrics, optim_type)\n"
      ],
      "metadata": {
        "id": "JXLQF8WAt3GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from psutil import cpu_count\n",
        "os.environ[\"OMP_NUM_THREADS\"] = f\"{cpu_count()}\"\n",
        "os.environ[\"OMP_WAIT_POLICY\"] = \"ACTIVE\"\n"
      ],
      "metadata": {
        "id": "dJy_IRIvt4ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.convert_graph_to_onnx\n",
        "import convert\n",
        "model_ckpt = \"transformersbook/distilbert-base-uncased-distilled-clinc\"\n",
        "onnx_model_path = Path(\"onnx/model.onnx\")\n",
        "convert(framework=\"pt\", model=model_ckpt, tokenizer=tokenizer, output=onnx_model_path, opset=12, pipeline_name=\"text-classification\")\n"
      ],
      "metadata": {
        "id": "_ewAuxVlt5oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime import (GraphOptimizationLevel, InferenceSession, SessionOptions)\n",
        "def create_model_for_provider(model_path, provider=\"CPUExecutionProvider\"):\n",
        "\toptions = SessionOptions()\n",
        "\toptions.intra_op_num_threads = 1\n",
        "\toptions.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\tsession = InferenceSession(str(model_path), options, providers=[provider])\n",
        "\tsession.disable_fallback()\n",
        "\treturn session\n",
        "\n",
        "onnx_model = create_model_for_provider(onnx_model_path)\n"
      ],
      "metadata": {
        "id": "odXdAvDPt6ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = clinc_enc[\"test\"][:1]\n",
        "del inputs[\"labels\"] l\n",
        "ogits_onnx = onnx_model.run(None, inputs)[0]\n",
        "logits_onnx.shape\n"
      ],
      "metadata": {
        "id": "ppmkMWkVt7bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(logits_onnx)"
      ],
      "metadata": {
        "id": "dJcdkdlmt9wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinc_enc[\"test\"][0][\"labels\"]"
      ],
      "metadata": {
        "id": "qEKBCE3Yt-zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "class OnnxPipeline:\n",
        "\tdef __init__(self, model, tokenizer):\n",
        "\t\tself.model = model\n",
        "\t\tself.tokenizer = tokenizer\n",
        "\tdef __call__(self, query):\n",
        "\t\tmodel_inputs = self.tokenizer(query, return_tensors=\"pt\")\n",
        "\t\tinputs_onnx = {k: v.cpu().detach().numpy() for k, v in model_inputs.items()}\n",
        "\t\tlogits = self.model.run(None, inputs_onnx)[0][0, :]\n",
        "\t\tprobs = softmax(logits)\n",
        "\t\tpred_idx = np.argmax(probs).item()\n",
        "\t\treturn [{\"label\": intents.int2str(pred_idx), \"score\": probs[pred_idx]}]\n"
      ],
      "metadata": {
        "id": "XGoqRWe7t_uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = OnnxPipeline(onnx_model, tokenizer) pipe(query)"
      ],
      "metadata": {
        "id": "3DnOPg48uA-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OnnxPerformanceBenchmark(PerformanceBenchmark):\n",
        "\tdef __init__(self, *args, model_path, **kwargs):\n",
        "\t\tsuper().__init__(*args, **kwargs)\n",
        "\t\tself.model_path = model_path\n",
        "\tdef compute_size(self):\n",
        "\t\tsize_mb = Path(self.model_path).stat().st_size / (1024 * 1024)\n",
        "\t\tprint(f\"Model size (MB) - {size_mb:.2f}\")\n",
        "\t\treturn {\"size_mb\": size_mb}\n"
      ],
      "metadata": {
        "id": "2dSuYDRYuB3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim_type = \"Distillation + ORT\"\n",
        "pb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type, model_path=\"onnx/model.onnx\")\n",
        "perf_metrics.update(pb.run_benchmark())\n",
        "Model size (MB) - 255.88\n",
        "Average latency (ms) - 21.02 +\\- 0.55\n",
        "Accuracy on test set - 0.868\n",
        "\n",
        "plot_metrics(perf_metrics, optim_type)\n"
      ],
      "metadata": {
        "id": "QY6jtJuguCvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "model_input = \"onnx/model.onnx\"\n",
        "model_output = \"onnx/model.quant.onnx\"\n",
        "quantize_dynamic(model_input, model_output, weight_type=QuantType.QInt8)\n"
      ],
      "metadata": {
        "id": "7fejotz4uDvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nnx_quantized_model = create_model_for_provider(model_output)\n",
        "pipe = OnnxPipeline(onnx_quantized_model, tokenizer)\n",
        "optim_type = \"Distillation + ORT (quantized)\"\n",
        "pb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type, model_path=model_output)\n",
        "perf_metrics.update(pb.run_benchmark()"
      ],
      "metadata": {
        "id": "sPq4jzTquEjq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}